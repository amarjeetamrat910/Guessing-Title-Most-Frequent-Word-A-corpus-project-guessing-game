{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b6fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d504823",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1= \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget tortor nec nisi mattis varius. Vivamus auctor est vitae eros bibendum, vel tincidunt nisi tincidunt. Donec id leo ut elit imperdiet venenatis. Integer sed ex eget turpis dapibus feugiat. Nunc et mauris eu nisi vulputate venenatis.\"\n",
    "\n",
    "corpus2= \"The quick brown fox jumps over the lazy dog. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ac libero eget dui consequat auctor vel id mauris. In hac habitasse platea dictumst.\"\n",
    "\n",
    "corpus3=\"Etiam nec velit eget ex fermentum lobortis. Nulla facilisi. Morbi vehicula mauris in felis vestibulum, id mollis velit consectetur. Donec in fermentum enim. Nam laoreet sapien id dolor finibus aliquam.\"\n",
    "\n",
    "corpus4= \"Suspendisse potenti. Ut eget justo ultrices, interdum libero non, vestibulum eros. Maecenas volutpat erat ac justo bibendum, at posuere est fermentum. Sed tincidunt dolor eget felis tincidunt, vel aliquam velit venenatis. Cras sit amet justo eget nisi vestibulum volutpat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bee69",
   "metadata": {},
   "source": [
    "# removing stopwords and special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee4b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words=[]\n",
    "\n",
    "for word in word_tokenize(corpus2):\n",
    "    if(word.lower()  not in  stopwords.words(\"english\") and len(word)>2):\n",
    "        \n",
    "        words.append(word.lower())\n",
    "        \n",
    "vocab=list(set(words))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63d64f",
   "metadata": {},
   "source": [
    "# creating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebbefd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fre = {}\n",
    "for word in vocab:\n",
    "    word_fre[word] = word_fre[word]=+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76f1ef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'consectetur': 1,\n",
       " 'fusce': 1,\n",
       " 'eget': 1,\n",
       " 'hac': 1,\n",
       " 'elit': 1,\n",
       " 'lazy': 1,\n",
       " 'auctor': 1,\n",
       " 'dolor': 1,\n",
       " 'platea': 1,\n",
       " 'sit': 1,\n",
       " 'quick': 1,\n",
       " 'adipiscing': 1,\n",
       " 'amet': 1,\n",
       " 'dog': 1,\n",
       " 'jumps': 1,\n",
       " 'vel': 1,\n",
       " 'ipsum': 1,\n",
       " 'consequat': 1,\n",
       " 'lorem': 1,\n",
       " 'habitasse': 1,\n",
       " 'fox': 1,\n",
       " 'libero': 1,\n",
       " 'brown': 1,\n",
       " 'dictumst': 1,\n",
       " 'dui': 1,\n",
       " 'mauris': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_fre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a9905",
   "metadata": {},
   "source": [
    "count the frequency  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63f85bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 quick\n",
      "1 brown\n",
      "1 fox\n",
      "1 jumps\n",
      "1 lazy\n",
      "1 dog\n",
      "1 lorem\n",
      "1 ipsum\n",
      "1 dolor\n",
      "1 sit\n",
      "1 amet\n",
      "1 consectetur\n",
      "1 adipiscing\n",
      "1 elit\n",
      "1 fusce\n",
      "1 libero\n",
      "1 eget\n",
      "1 dui\n",
      "1 consequat\n",
      "1 auctor\n",
      "1 vel\n",
      "1 mauris\n",
      "1 hac\n",
      "1 habitasse\n",
      "1 platea\n",
      "1 dictumst\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "\n",
    "for word in word_tokenize(corpus2):\n",
    "    if(word.lower()  not in  stopwords.words(\"english\") and len(word)>2):\n",
    "        \n",
    "        words.append(word.lower())\n",
    "for word in words:\n",
    "    print(word_fre[word],word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d628f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consectetur\n",
      "fusce\n",
      "eget\n",
      "hac\n",
      "elit\n",
      "lazy\n",
      "auctor\n",
      "dolor\n",
      "platea\n",
      "sit\n",
      "quick\n",
      "adipiscing\n",
      "amet\n",
      "dog\n",
      "jumps\n",
      "vel\n",
      "ipsum\n",
      "consequat\n",
      "lorem\n",
      "habitasse\n",
      "fox\n",
      "libero\n",
      "brown\n",
      "dictumst\n",
      "dui\n",
      "mauris\n"
     ]
    }
   ],
   "source": [
    "for keys in word_fre.keys():\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e1ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a59ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cfdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
